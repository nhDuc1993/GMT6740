{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "from DummyMaker import GetDummies\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Required Variables\n",
    "Folder = \"E:\\\\datasets\\\\car\\\\\"\n",
    "NumericalColumns = [\"mileage\", \"engine_displacement\", \"engine_power\"]\n",
    "ConvertToStringColumns = [\"stk_year\", \"door_count\", \"seat_count\", \"manufacture_year\"]\n",
    "PriceColumn = [\"price_eur\"]\n",
    "StringColumns = [\n",
    "    \"type\",  # Combination of Maker and Model\n",
    "    \"manufacture_year\",\n",
    "    \"body_type\",\n",
    "    \"stk_year\",\n",
    "    \"transmission\",\n",
    "    \"door_count\",\n",
    "    \"seat_count\",\n",
    "    \"fuel_type\",\n",
    "]\n",
    "\n",
    "# Try Reading Parquet for fast read.\n",
    "try:\n",
    "    Data = pd.read_parquet(f\"{Folder}clean_df.parq\")\n",
    "except:\n",
    "    Data = pd.read_csv(f\"{Folder}clean_df.csv\", low_memory=False)\n",
    "    Data.to_parquet(f\"{Folder}clean_df.parq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Copy\n",
    "TData = Data.copy()\n",
    "TData[\"type\"] = (\n",
    "    TData[\"maker\"].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    "    + \"_\"\n",
    "    + TData[\"model\"].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    ")\n",
    "\n",
    "# Remove Unwanted Variables\n",
    "UnWantedVariables = [] + [\"date_created\", \"date_last_seen\", \"model\", \"maker\"]\n",
    "for x in UnWantedVariables:\n",
    "    if x in TData.columns:\n",
    "        del TData[x]\n",
    "\n",
    "# Get rid of some columns\n",
    "for c in ConvertToStringColumns:\n",
    "    TData[c] = TData[c].apply(lambda x: str(x) if not pd.isnull(x) else x)\n",
    "\n",
    "# Reorder\n",
    "TData = TData[StringColumns + NumericalColumns + PriceColumn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    TData[StringColumns + NumericalColumns],\n",
    "    TData[PriceColumn],\n",
    "    test_size=0.20,\n",
    "    random_state=1991,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Numerical Columns\n",
    "NumericalScaler = StandardScaler().fit(X_train[NumericalColumns])\n",
    "X_train[NumericalColumns] = NumericalScaler.transform(X_train[NumericalColumns])\n",
    "\n",
    "# Scale Price\n",
    "PriceScaler = StandardScaler().fit(y_train)\n",
    "y_train = PriceScaler.transform(y_train).flatten()\n",
    "\n",
    "# Scale Test Data\n",
    "X_test[NumericalColumns] = NumericalScaler.transform(X_test[NumericalColumns])\n",
    "y_test= PriceScaler.transform(y_test).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Categorical Variables\n",
    "# https://dantegates.github.io/2018/05/04/a-fast-one-hot-encoder-with-sklearn-and-pandas.html\n",
    "Encoder = GetDummies().fit(X_train[StringColumns])\n",
    "\n",
    "# Store Column Names\n",
    "ColumnNames = list(Encoder.final_columns) + NumericalColumns\n",
    "\n",
    "# Transform Training\n",
    "Coded_X_train = Encoder.transform(X_train[StringColumns])\n",
    "\n",
    "# Transform Testing\n",
    "Coded_X_test = Encoder.transform(X_test[StringColumns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Everything to Sparse Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underlying function returns sparse data\n",
    "\n",
    "Coded_X_train = Coded_X_train.sparse.to_coo().tocsr()\n",
    "\n",
    "Coded_X_train_NAN = Coded_X_train.copy()\n",
    "\n",
    "Coded_X_test = Coded_X_test.sparse.to_coo().tocsr()\n",
    "\n",
    "Coded_X_test_NAN = Coded_X_test.copy()\n",
    "\n",
    "\n",
    "# Add Numerical Columns too\n",
    "for c in NumericalColumns:\n",
    "    Coded_X_train = hstack([Coded_X_train, sparse.csr_matrix(X_train[c].fillna(0)).T])\n",
    "\n",
    "    Coded_X_train_NAN = hstack([Coded_X_train_NAN, sparse.csr_matrix(X_train[c]).T])\n",
    "\n",
    "    Coded_X_test = hstack([Coded_X_test, sparse.csr_matrix(X_test[c].fillna(0)).T])\n",
    "\n",
    "    Coded_X_test_NAN = hstack([Coded_X_test_NAN, sparse.csr_matrix(X_test[c]).T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Data,TData,X_test,X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52845"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Learning with SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40080402, 0.5965793 , 0.98412273, 0.36599672, 0.32208589,\n",
       "       0.30134911, 0.24730033, 0.20844189, 0.18130061, 0.14121844,\n",
       "       0.11738998, 0.10872461, 0.08431483, 0.08180115, 0.07915188,\n",
       "       0.07037344, 0.0699454 , 0.06670425, 0.06286014, 0.05917537,\n",
       "       0.05349643, 0.05108214, 0.04964976, 0.04850583, 0.04705939])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8340.832875</td>\n",
       "      <td>1900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13476.299437</td>\n",
       "      <td>13851.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8579.668409</td>\n",
       "      <td>8393.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19235.647413</td>\n",
       "      <td>16494.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13577.392446</td>\n",
       "      <td>6250.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted     Price\n",
       "0   8340.832875   1900.00\n",
       "1  13476.299437  13851.04\n",
       "2   8579.668409   8393.19\n",
       "3  19235.647413  16494.00\n",
       "4  13577.392446   6250.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6628859643206464"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=6,random_state=1991).fit(Coded_X_train)\n",
    "display(tsvd.explained_variance_)\n",
    "\n",
    "ReducedTrain = tsvd.transform(Coded_X_train)\n",
    "ReducedTest = tsvd.transform(Coded_X_test)\n",
    "\n",
    "X_parts = np.vsplit(ReducedTrain,8)\n",
    "y_parts = np.vsplit(y_train.reshape((y_train.shape[0],1)),8)\n",
    "\n",
    "sgd = SGDRegressor(random_state=1991)\n",
    "\n",
    "for i,x in enumerate(X_parts):\n",
    "    sgd.partial_fit(x,y_parts[i].flatten())\n",
    "\n",
    "y_pred = sgd.predict(ReducedTest)\n",
    "\n",
    "Comparison = pd.concat(\n",
    "    [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "Comparison = pd.concat(\n",
    "    [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "    axis=1,\n",
    ")\n",
    "Comparison = pd.DataFrame(\n",
    "    PriceScaler.inverse_transform(Comparison), columns=[\"Predicted\", \"Price\"]\n",
    ")\n",
    "print(len(Comparison))\n",
    "display(Comparison.head())\n",
    "r2_score(Comparison[\"Price\"], Comparison[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbors Regressor With Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40225702, 0.59461437, 0.98411756, 0.36609849, 0.32189105,\n",
       "       0.30154424, 0.24753535, 0.20815263, 0.18138634, 0.14140372])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1900.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12674.473610</td>\n",
       "      <td>13851.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7672.058044</td>\n",
       "      <td>8393.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16494.000000</td>\n",
       "      <td>16494.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6515.383281</td>\n",
       "      <td>6250.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted     Price\n",
       "0   1900.000000   1900.00\n",
       "1  12674.473610  13851.04\n",
       "2   7672.058044   8393.19\n",
       "3  16494.000000  16494.00\n",
       "4   6515.383281   6250.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8884038388144765"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=6,random_state=1991).fit(Coded_X_train)\n",
    "display(tsvd.explained_variance_)\n",
    "\n",
    "ReducedTrain = tsvd.transform(Coded_X_train)\n",
    "ReducedTest = tsvd.transform(Coded_X_test)\n",
    "\n",
    "kn = KNeighborsRegressor(25, weights=\"distance\")\n",
    "kn.fit(ReducedTrain, y_train)\n",
    "y_pred = kn.predict(ReducedTest)\n",
    "\n",
    "\n",
    "Comparison = pd.concat(\n",
    "    [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "Comparison = pd.concat(\n",
    "    [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "    axis=1,\n",
    ")\n",
    "Comparison = pd.DataFrame(\n",
    "    PriceScaler.inverse_transform(Comparison), columns=[\"Predicted\", \"Price\"]\n",
    ")\n",
    "print(len(Comparison))\n",
    "display(Comparison.head())\n",
    "r2_score(Comparison[\"Price\"], Comparison[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/256172/why-is-dimensionality-reduction-always-done-before-clustering\n",
    "\n",
    "https://community.databricks.com/t5/machine-learning/do-one-hot-encoding-ohe-before-or-after-split-data-to-train-and/td-p/17888#:~:text=%22If%20you%20perform%20the%20encoding,scores%20but%20poor%20in%20deployment).\n",
    "\n",
    "https://datascience.stackexchange.com/questions/107714/encoding-before-vs-after-train-test-split\n",
    "\n",
    "https://stats.stackexchange.com/questions/599508/do-we-one-hot-encode-create-dummy-variables-before-or-after-train-test-split\n",
    "\n",
    "https://stats.stackexchange.com/questions/142216/zero-centering-the-testing-set-after-pca-on-the-training-set\n",
    "\n",
    "https://stats.stackexchange.com/questions/55718/pca-and-the-train-test-split\n",
    "\n",
    "https://stackoverflow.com/questions/55441022/how-to-aply-the-same-pca-to-train-and-test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "\n",
    "https://stackoverflow.com/questions/33603787/performing-pca-on-large-sparse-matrix-by-using-sklearn\n",
    "\n",
    "https://stackoverflow.com/questions/26576524/how-do-i-transform-a-scipy-sparse-matrix-to-a-numpy-matrix\n",
    "\n",
    "https://stackoverflow.com/questions/20459536/convert-pandas-dataframe-to-sparse-numpy-matrix-directly\n",
    "\n",
    "https://dantegates.github.io/2018/05/04/a-fast-one-hot-encoder-with-sklearn-and-pandas.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.SparseDtype.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.arrays.SparseArray.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Vs Truncated SVD on KNeighborsRegressor(25, weights=\"distance\")\n",
    "\n",
    "PCA doesn't work on sparse Data.\n",
    "\n",
    "2 Componenets\n",
    "PCA yielded higher Accuracy at 2 components of 0.8178726424680244 vs 0.623305478122284 of Truncated SVD using seed 1991.\n",
    "\n",
    "6 Componenets\n",
    "PCA yielded Accuracy at 6 components of 0.8832974168967355 vs 0.8830232140933794 of Truncated SVD using seed 1991.\n",
    "\n",
    "PCA Explained Variance ([1.79120925, 0.98414093, 0.389263  , 0.33659156, 0.30127252,\n",
    "       0.27814113]) in 1m 26s\n",
    "\n",
    "TSVD explained Variance ([1.39979887, 0.5979397 , 0.98411531, 0.36582389, 0.32243568,\n",
    "       0.30120099]) in 22s\n",
    "\n",
    "Adding more than 6 components yields very low improvement.\n",
    "\n",
    "Isomap too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K Neighbors Regressor With PCA\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# DenseTraining =Coded_X_train.toarray()\n",
    "\n",
    "# pca = PCA(n_components=6,random_state=1991).fit(DenseTraining)\n",
    "# display(pca.explained_variance_)\n",
    "\n",
    "# ReducedTrain = pca.transform(DenseTraining)\n",
    "# ReducedTest = pca.transform(Coded_X_test.toarray())\n",
    "\n",
    "# kn = KNeighborsRegressor(25, weights=\"distance\")\n",
    "# kn.fit(ReducedTrain, y_train)\n",
    "# y_pred = kn.predict(ReducedTest)\n",
    "\n",
    "\n",
    "# Comparison = pd.concat(\n",
    "#     [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# Comparison = pd.concat(\n",
    "#     [pd.DataFrame(y_pred), pd.DataFrame(y_test)],\n",
    "#     axis=1,\n",
    "# )\n",
    "# Comparison = pd.DataFrame(\n",
    "#     PriceScaler.inverse_transform(Comparison), columns=[\"Predicted\", \"Price\"]\n",
    "# )\n",
    "# print(len(Comparison))\n",
    "# display(Comparison.head())\n",
    "# r2_score(Comparison[\"Price\"], Comparison[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustiner\n",
    "\n",
    "DBSCAN, HDBSCAN (Very slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Regrossor\n",
    "\n",
    "0.7273975600580911 accuracy on raw data using seed 1991\n",
    "\n",
    "0.6312 on Truncated SVD data with 6 components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
