{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder = \"E:\\\\datasets\\\\car\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumericalColumns = [\"mileage\", \"engine_displacement\", \"engine_power\"]\n",
    "ConvertToStringColumns = [\"stk_year\", \"door_count\", \"seat_count\", \"manufacture_year\"]\n",
    "PriceColumn = [\"price_eur\"]\n",
    "StringColumns = [\n",
    "    \"type\",  # Combination of Maker and Model\n",
    "    \"manufacture_year\",\n",
    "    \"body_type\",\n",
    "    \"stk_year\",\n",
    "    \"transmission\",\n",
    "    \"door_count\",\n",
    "    \"seat_count\",\n",
    "    \"fuel_type\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & Convert to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Data = pd.read_parquet(f\"{Folder}clean_df.parq\")\n",
    "except:\n",
    "    Data = pd.read_csv(f\"{Folder}clean_df.csv\", low_memory=False)\n",
    "    Data.to_parquet(f\"{Folder}clean_df.parq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an Extra Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TData = Data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Maker and Model\n",
    "Model is dependent on Maker. We shouldn't model maker separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TData[\"type\"] = (\n",
    "    TData[\"maker\"].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    "    + \"_\"\n",
    "    + TData[\"model\"].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Any Unwanted Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnWantedVariables = [] + [\"date_created\", \"date_last_seen\", \"model\", \"maker\"]\n",
    "for x in UnWantedVariables:\n",
    "    if x in TData.columns:\n",
    "        del TData[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform some columns to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ConvertToStringColumns:\n",
    "    TData[c] = TData[c].apply(lambda x: str(x) if not pd.isnull(x) else x)\n",
    "\n",
    "TData = TData[StringColumns + NumericalColumns + PriceColumn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TData['type'].value_counts().to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TData.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumericalScaler = StandardScaler().fit(TData[NumericalColumns])\n",
    "TData[NumericalColumns] = NumericalScaler.transform(TData[NumericalColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NumericalScaler.obj\", \"wb\") as NS_File:\n",
    "    pickle.dump(NumericalScaler, NS_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PriceScaler = StandardScaler().fit(TData[PriceColumn])\n",
    "TData[PriceColumn] = PriceScaler.transform(TData[PriceColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PriceScaler.obj\", \"wb\") as PS_File:\n",
    "    pickle.dump(PriceScaler, PS_File)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/28465633/easy-way-to-apply-transformation-from-pandas-get-dummies-to-new-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded = pd.get_dummies(TData, columns=StringColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HeadObject = Encoded.head(1)\n",
    "with open(\"HeadObject.obj\", \"wb\") as HO_File:\n",
    "    pickle.dump(HeadObject, HO_File)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill remaining nans with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded = Encoded.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store tp Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded.head().to_parquet(f\"{Folder}SampleEncoded.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded.to_parquet(f\"{Folder}Encoded.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Encoded[[x for x in Encoded.columns if x != \"price_eur\"]]\n",
    "X.to_parquet(f\"{Folder}X.parq\")\n",
    "y = Encoded[[\"price_eur\"]]\n",
    "y.to_parquet(f\"{Folder}y.parq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
