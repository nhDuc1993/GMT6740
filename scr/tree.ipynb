{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>manufacture_year</th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>engine_power</th>\n",
       "      <th>body_type</th>\n",
       "      <th>stk_year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>door_count</th>\n",
       "      <th>seat_count</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_last_seen</th>\n",
       "      <th>price_eur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ford</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>138.12506</td>\n",
       "      <td>compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>man</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>diesel</td>\n",
       "      <td>2015-11-14 18:10:06.838319+00</td>\n",
       "      <td>2016-01-27 20:40:15.46361+00</td>\n",
       "      <td>10584.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skoda</td>\n",
       "      <td>octavia</td>\n",
       "      <td>143476.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>108.62262</td>\n",
       "      <td>compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>man</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>diesel</td>\n",
       "      <td>2015-11-14 18:10:06.853411+00</td>\n",
       "      <td>2016-01-27 20:40:15.46361+00</td>\n",
       "      <td>8882.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97676.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>113.98670</td>\n",
       "      <td>compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>man</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>diesel</td>\n",
       "      <td>2015-11-14 18:10:06.861792+00</td>\n",
       "      <td>2016-01-27 20:40:15.46361+00</td>\n",
       "      <td>12065.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>111970.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>84.48426</td>\n",
       "      <td>compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>man</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2015-11-14 18:10:06.872313+00</td>\n",
       "      <td>2016-01-27 20:40:15.46361+00</td>\n",
       "      <td>2960.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skoda</td>\n",
       "      <td>fabia</td>\n",
       "      <td>128886.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>84.48426</td>\n",
       "      <td>compact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>man</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2015-11-14 18:10:06.880335+00</td>\n",
       "      <td>2016-01-27 20:40:15.46361+00</td>\n",
       "      <td>2738.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maker    model   mileage  manufacture_year  engine_displacement  \\\n",
       "0   ford   galaxy  151000.0            2011.0               2000.0   \n",
       "1  skoda  octavia  143476.0            2012.0               2000.0   \n",
       "2    bmw      NaN   97676.0            2010.0               1995.0   \n",
       "3  skoda    fabia  111970.0            2004.0               1200.0   \n",
       "4  skoda    fabia  128886.0            2004.0               1200.0   \n",
       "\n",
       "   engine_power body_type  stk_year transmission  door_count  seat_count  \\\n",
       "0     138.12506   compact       NaN          man         5.0         7.0   \n",
       "1     108.62262   compact       NaN          man         5.0         5.0   \n",
       "2     113.98670   compact       NaN          man         5.0         5.0   \n",
       "3      84.48426   compact       NaN          man         5.0         5.0   \n",
       "4      84.48426   compact       NaN          man         5.0         5.0   \n",
       "\n",
       "  fuel_type                   date_created                date_last_seen  \\\n",
       "0    diesel  2015-11-14 18:10:06.838319+00  2016-01-27 20:40:15.46361+00   \n",
       "1    diesel  2015-11-14 18:10:06.853411+00  2016-01-27 20:40:15.46361+00   \n",
       "2    diesel  2015-11-14 18:10:06.861792+00  2016-01-27 20:40:15.46361+00   \n",
       "3  gasoline  2015-11-14 18:10:06.872313+00  2016-01-27 20:40:15.46361+00   \n",
       "4  gasoline  2015-11-14 18:10:06.880335+00  2016-01-27 20:40:15.46361+00   \n",
       "\n",
       "   price_eur  \n",
       "0   10584.75  \n",
       "1    8882.31  \n",
       "2   12065.06  \n",
       "3    2960.77  \n",
       "4    2738.71  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = r\"D:/clean_df.csv\"\n",
    "df = pd.read_csv(link)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create man_period, stk_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_created'] = pd.to_datetime(df['date_created'])\n",
    "df['year_created'] = df['date_created'].dt.year\n",
    "\n",
    "df['man_period'] = df['year_created'] - df['manufacture_year']\n",
    "df['stk_period'] = df['year_created'] - df['stk_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['manufacture_year', 'stk_year', 'date_created', 'date_last_seen', 'year_created'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indicator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        nonnull_X = np.nan_to_num(X.astype(float), nan=0).astype(int)\n",
    "\n",
    "        missing_indicator = MissingIndicator()\n",
    "        indicator_values = missing_indicator.fit_transform(X).astype(int)\n",
    "\n",
    "        return np.c_[nonnull_X, indicator_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['engine_power', 'mileage', 'engine_displacement']\n",
    "conv_to_string_columns = ['door_count', 'seat_count', 'man_period', 'stk_period']\n",
    "categorical_columns = ['maker', 'model', 'body_type', 'transmission', 'fuel_type']+conv_to_string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "indicator = Indicator()\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", indicator, numerical_columns),\n",
    "    (\"cat\", one_hot_encoder , categorical_columns),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def datatype_converter(x):\n",
    "\n",
    "#     for i in conv_to_string_columns:\n",
    "#         x[i] = x[i].apply(lambda x: str(x) if not pd.isnull(x) else x)\n",
    "    \n",
    "#     for i in categorical_columns:\n",
    "#         x[i] = x[i].astype('category')\n",
    "    \n",
    "#     x[numerical_columns] = x[numerical_columns].apply(pd.to_numeric, downcast=\"float\")\n",
    "#     x['price_eur'] = x['price_eur'].apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "#     return x\n",
    "\n",
    "# df = datatype_converter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, val, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price_eur', axis=1)\n",
    "y = df['price_eur']\n",
    "\n",
    "full_pipeline.fit(X)\n",
    "X_trans = full_pipeline.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_trans, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  # Splitting criterion\n",
    "    'splitter': ['best', 'random'],     # Strategy for choosing splits\n",
    "    'max_depth': [10, 20, 30],     # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],    # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],      # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for the best split\n",
    "}\n",
    "\n",
    "dt_rs = RandomizedSearchCV(\n",
    "    estimator=dt_reg,\n",
    "    param_distributions=dt_param_grid,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    n_iter=30,  # Number of parameter candidate settings to sample\n",
    "    verbose=2,  # The higher this is, the more messages are outputed\n",
    "    random_state=42,\n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.4s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'mini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nhduc\\OneDrive\\Desktop\\6740project\\GMT6740\\scr\\tree.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nhduc/OneDrive/Desktop/6740project/GMT6740/scr/tree.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dt_rs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1316\u001b[0m         X,\n\u001b[0;32m   1317\u001b[0m         y,\n\u001b[0;32m   1318\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1319\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1320\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    166\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    167\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    169\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39mif\u001b[39;00m validate_separately:\n\u001b[0;32m    573\u001b[0m     \u001b[39m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[39m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[39m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[39m# :(\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     check_X_params, check_y_params \u001b[39m=\u001b[39m validate_separately\n\u001b[1;32m--> 578\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    579\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'mini'"
     ]
    }
   ],
   "source": [
    "dt_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'mini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nhduc\\OneDrive\\Desktop\\6740project\\GMT6740\\scr\\tree.ipynb Cell 18\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nhduc/OneDrive/Desktop/6740project/GMT6740/scr/tree.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dt_reg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1316\u001b[0m         X,\n\u001b[0;32m   1317\u001b[0m         y,\n\u001b[0;32m   1318\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1319\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1320\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    166\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    167\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    169\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39mif\u001b[39;00m validate_separately:\n\u001b[0;32m    573\u001b[0m     \u001b[39m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[39m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[39m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[39m# :(\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     check_X_params, check_y_params \u001b[39m=\u001b[39m validate_separately\n\u001b[1;32m--> 578\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params)\n\u001b[0;32m    579\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nhduc\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'mini'"
     ]
    }
   ],
   "source": [
    "dt_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
